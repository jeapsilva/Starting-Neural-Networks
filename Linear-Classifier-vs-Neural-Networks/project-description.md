# Project Description

This project aims to demonstrate how a neural network has advantages compared to a linear classifier (perceptron). Furthermore, this project shows how the forward and backpropagation steps occur in a neural network.

In the forwarding step, the weight functions start with random valuesâ€‹. After that,  information is passed through the neural network. I've used the Cross-Entropy Loss, which has been implemented in many algorithms.

In the backpropagation step, was calculated the derivatives formulas to also calculate the weights actualization using the descent gradient.

I hope you enjoy this explanation. 
